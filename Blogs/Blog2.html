<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Nimsara Jayathilaka | Portfolio | Blog</title>
    <link href='https://unpkg.com/boxicons@2.1.4/css/boxicons.min.css' rel='stylesheet'>
    <link rel="stylesheet" href="../style.css">
    <link rel="icon" href="https://www.gstatic.com/images/branding/product/1x/google_fonts_64dp.png"
        type="image/x-icon">
    <!-- <link rel="icon" href="https://www.google.com/url?sa=i&url=https%3A%2F%2Fstock.adobe.com%2Fsearch%3Fk%3Dnj%2Blogo&psig=AOvVaw3wCaJtjIUOKJnuGSAe6W4J&ust=1728380094863000&source=images&cd=vfe&opi=89978449&ved=0CBQQjRxqFwoTCIi04-T7-4gDFQAAAAAdAAAAABAE"
            type="image/x-icon"> -->
    <script src="https://unpkg.com/scrollreveal"></script>
</head>

<body>
    <header class="header">
        <a href="#" class="logo">NIMSARA</a>
        <nav class="navbar">
            <a href="../index.html">Home</a>
            <a href="../index.html">About</a>
            <a href="../index.html">Tech</a>
            <a href="../index.html">Service</a>
            <a href="../index.html">Portfolio</a>
            <a href="../index.html">Contact</a>
            <div class="dropdown">
                <button class="dropbtn">
                    Blogs
                </button>
                <div class="dropdown-content">
                    <a href="./Blog1.html"><i class='bx bx-brain'></i>AI & ML</i></a>
                    <a href="#"><i class='bx bx-globe'></i></i>Tech Revolution</i></a>
                    <a class="active" href="./Blog2.html"><i class='bx bx-cloud-upload'></i></i>LLM Models</i></a>
                </div>
            </div>

            <button class="button" onclick="SheduleMeet()">
                <svg class="svgIcon" viewBox="0 0 512 512" height="1em" xmlns="http://www.w3.org/2000/svg">
                    <path
                        d="M256 512A256 256 0 1 0 256 0a256 256 0 1 0 0 512zm50.7-186.9L162.4 380.6c-19.4 7.5-38.5-11.6-31-31l55.5-144.3c3.3-8.5 9.9-15.1 18.4-18.4l144.3-55.5c19.4-7.5 38.5 11.6 31 31L325.1 306.7c-3.2 8.5-9.9 15.1-18.4 18.4zM288 256a32 32 0 1 0 -64 0 32 32 0 1 0 64 0z">
                    </path>
                </svg>
                Shedule a Meet
            </button>
        </nav>
        <i class="bx bx-menu" id="menu-icon"></i>
    </header>

    <section class="Blog" id="Blog">
        <div class="Blog-heading">
            <h2 class="heading">large language model <span>(LLM)?</span></h2>
        </div>
        <div class="blogIntro">
            <div class="left-img">
                <img src="../Assets/Blogs/large-language-model-7563532-final-9e350e9fa02d4685887aa061af7a2de2.png"
                    alt="">
            </div>
            <article class="right-Intro">
                <h4>large language model (LLM)</h4>
                <p>A large language model (LLM) is a type of artificial intelligence (AI) program that can recognize and
                    generate text, among other tasks. LLMs are trained on huge sets of data — hence the name "large."
                    LLMs are built on machine learning: specifically, a type of neural network called a transformer
                    model.</p>
                <p>In simpler terms, an LLM is a computer program that has been fed enough examples to be able to
                    recognize and interpret human language or other types of complex data. Many LLMs are trained on data
                    that has been gathered from the Internet — thousands or millions of gigabytes' worth of text. But
                    the quality of the samples impacts how well LLMs will learn natural language, so an LLM's
                    programmers may use a more curated data set.</p>
                <p>LLMs use a type of machine learning called deep learning in order to understand how characters,
                    words, and sentences function together. Deep learning involves the probabilistic analysis of
                    unstructured data, which eventually enables the deep learning model to recognize distinctions
                    between pieces of content without human intervention.</p>
                <p>LLMs are then further trained via tuning: they are fine-tuned or prompt-tuned to the particular task
                    that the programmer wants them to do, such as interpreting questions and generating responses, or
                    translating text from one language to another.</p>
            </article>
        </div>
    </section>

    <section class="IntroDes">
        <article class="left-intro">
            <h4 class="SubHeading">
                What are <span>LLMs used for?</span>
            </h4>
            <p>
                LLMs can be trained to do a number of tasks. One of the most well-known uses is their application as
                generative AI: when given a prompt or asked a question, they can produce text in reply. The publicly
                available LLM ChatGPT, for instance, can generate essays, poems, and other textual forms in response to
                user inputs.

                Any large, complex data set can be used to train LLMs, including programming languages. Some LLMs can
                help programmers write code. They can write functions upon request — or, given some code as a starting
                point, they can finish writing a program. LLMs may also be used in:

                Sentiment analysis
                DNA research
                Customer service
                Chatbots
                Online search</p>
            <p>
                Examples of real-world LLMs include ChatGPT (from OpenAI), Bard (Google), Llama (Meta), and Bing Chat
                (Microsoft). GitHub's Copilot is another example, but for coding instead of natural human language
            </p>
        </article>
        <article class="right-Intro">
            <h4 class="SubHeading">
                What are some <span>advantages and limitations of LLMs? </span>
            </h4>
            <p>
                A key characteristic of LLMs is their ability to respond to unpredictable queries. A traditional
                computer program receives commands in its accepted syntax, or from a certain set of inputs from the
                user. A video game has a finite set of buttons, an application has a finite set of things a user can
                click or type, and a programming language is composed of precise if/then statements.

                By contrast, an LLM can respond to natural human language and use data analysis to answer an
                unstructured question or prompt in a way that makes sense. Whereas a typical computer program would not
                recognize a prompt like "What are the four greatest funk bands in history?", an LLM might reply with a
                list of four such bands, and a reasonably cogent defense of why they are the best.

                In terms of the information they provide, however, LLMs can only be as reliable as the data they ingest.
                If fed false information, they will give false information in response to user queries. LLMs also
                sometimes "hallucinate": they create fake information when they are unable to produce an accurate
                answer. For example, in 2022 news outlet Fast Company asked ChatGPT about the company Tesla's previous
                financial quarter; while ChatGPT provided a coherent news article in response, much of the information
                within was invented.

                In terms of security, user-facing applications based on LLMs are as prone to bugs as any other
                application. LLMs can also be manipulated via malicious inputs to provide certain types of responses
                over others — including responses that are dangerous or unethical. Finally, one of the security problems
                with LLMs is that users may upload secure, confidential data into them in order to increase their own
                productivity. But LLMs use the inputs they receive to further train their models, and they are not
                designed to be secure vaults; they may expose confidential data in response to queries from other users.
            </p>
        </article>
    </section>
    <section class="explain">
        <div class="explain-heading">
            <h2 class="heading">How do <span>LLMs work?</span></h2>
        </div>
        <div class="explain-content">
            
            <h4>Machine Learning and Deep Learning</h4>
            <p>At the core of large language models (LLMs) is machine learning, a branch of artificial intelligence
                (AI). Machine learning involves feeding a system large amounts of data so that it can learn to identify
                patterns and features without direct human intervention. LLMs use a specific form of machine learning
                known as deep learning. In deep learning, models become capable of learning on their own by identifying
                intricate patterns across vast data sets. These models are trained to use probability to predict likely
                outcomes. For example, when analyzing the sentence "The quick brown fox jumped over the lazy dog," a
                deep learning model might observe that the letters "e" and "o" appear more frequently, which helps it
                identify common characters in English text. Though a single sentence doesn’t provide sufficient data to
                draw conclusions, deep learning models analyze trillions of sentences to make predictions, such as
                completing sentences or generating new text.</p>

            <h4>Neural Networks</h4>
            <p>LLMs are powered by neural networks, which mimic the way neurons work in the human brain. In an
                artificial neural network, data passes through a series of interconnected nodes, also called neurons,
                that are organized in layers. These layers include an input layer (which receives the raw data), an
                output layer (which delivers the final result), and hidden layers in between. Information only moves
                forward when certain conditions or thresholds are met within the network. This layered structure enables
                neural networks to learn complex representations of data, such as distinguishing nuanced aspects of
                human language. The deeper and more sophisticated the network, the more capable it becomes of handling
                intricate patterns and data relationships.</p>

            <h4>Transformer Models</h4>
            <p>The neural networks used by LLMs are typically transformer models. Unlike other machine learning models,
                transformer models excel at understanding context, which is crucial in processing human language. They
                use a technique called "self-attention," allowing the model to weigh different parts of a sequence (such
                as words in a sentence) to understand how they relate to one another. This helps LLMs detect the
                relationships between different parts of a sentence or even across entire paragraphs. For instance, they
                can interpret how the end of a sentence connects to the beginning or how different sentences in a text
                interact, making them better at capturing the intricacies of human communication. The self-attention
                mechanism also allows LLMs to recognize the meaning behind words and phrases based on the context in
                which they appear, improving their ability to generate and interpret natural language.</p>

            <h4>Building LLMs with Cloudflare</h4>
            <p>Developing LLMs requires substantial data and storage infrastructure, which can be costly for developers.
                Traditionally, training data is spread across multiple locations, and moving this data to a central hub
                can incur significant egress fees. To help developers build LLM applications more efficiently,
                Cloudflare offers solutions such as Vectorize, a globally distributed vector database that allows for
                querying data without egress fees. Data can be stored in Cloudflare's R2 object storage or in Workers
                Key Value, enabling developers to access their data with minimal cost. Additionally, Cloudflare Workers
                AI provides a development platform where developers can experiment with and deploy their LLMs. This
                combination of tools allows developers to quickly build, test, and iterate on their LLM applications
                without requiring heavy infrastructure investments.</p>



            <p><i class='bx bx-brain'></i><i>Refferences : <a
                        href="https://www.cloudflare.com/learning/ai/what-is-large-language-model/">Click here to
                        Clouds Flaire</a></i></p>


        </div>

    </section>
    <footer class="footer">
        <div class="footer-text">
            <p>Copyright &copy; 24 by Nimsara Jayathilaka | All Right Reserved.</p>
        </div>

        <div class="footer-iconTop">
            <a href="#Blog"><i class="bx bx-up-arrow-alt"></i></a>
        </div>
    </footer>
</body>

</html>